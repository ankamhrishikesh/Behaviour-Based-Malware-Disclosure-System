import pandas as pd
import numpy as np 
import matplotlib.pyplot as plt
import seaborn as sns
malData=pd.read_csv("MalwareData.csv", sep="|", low_memory =True )
from sklearn.model_selection import train_test_split
# Assuming you have already loaded and preprocessed the data as malData
# Extract the target labels (assuming "legitimate" column contains the labels)
y = malData["legitimate"]
# Split the data into train and test sets
X_train, X_test, y_train, y_test = train_test_split(malData, y, test_size=0.2, random_state=42)
# Create the oversampler
oversampler = RandomOverSampler(random_state=42)
# Perform the oversampling only on the training set
X_train_resampled, y_train_resampled = oversampler.fit_resample(X_train, y_train)
# Check the new class distribution
print(pd.Series(y_train_resampled).value_counts())
malData.head()
malData.shape
legit=  malData[0:41323]
mal= malData[41323::]
print("The shape of the legit dataset is: %s samples, %s features"%(legit.shape[0],legit.shape[1]))
print("The shape of the mal dataset is: %s samples, % s features" %(mal.shape[0],mal.shape[1]))
fig = plt.figure()
ax = fig.add_axes([0,0,1,1])
ax.hist(malData['legitimate'],20)
plt.show()
y=malData['legitimate']
malData=malData.drop(['legitimate'],axis=1)
malData=malData.drop(['Name'],axis=1)
malData=malData.drop(['md5'],axis=1)
print(" The Name and md5 variables are removed successfully")
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(malData,y, test_size=0.2, random_state=42)
X_train.shape
from sklearn.metrics import f1_score,accuracy_score,confusion_matrix,auc,confusion_matrix
from sklearn.ensemble import RandomForestClassifier
from sklearn.datasets import make_classification
clf = RandomForestClassifier(max_depth=2, random_state=0)
randomModel=clf.fit(X_train, y_train)
#  Accuracy on the train dataset
train_pred=randomModel.predict(X_train)
accuracy_score(y_train,train_pred)
# Accuracy on the test dataset
prediction=randomModel.predict(X_test)
accuracy_score(y_test,prediction)
f1_score(y_test, prediction)
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
# Define model
model = Sequential()
model.add(Dense(16, input_dim=54, activation= "relu"))
model.add(Dense(8, activation= "relu"))
model.add(Dense(4, activation= "relu"))
model.add(Dense(1, activation='sigmoid'))
model.summary() #Print model Summary
# Compile model
model.compile(loss= "binary_crossentropy" , optimizer="rmsprop", metrics=["accuracy"])
# Fit Model
model.fit(X_train, y_train, epochs=5, batch_size=42)
# Accuracy on the training dataset
trainPred=model.predict(X_train)
trainPred=[1 if y>= 0.5 else 0   for y in trainPred]
accuracy_score(y_train,trainPred)
# Accuracy on the test dataset
y_prediction=model.predict(X_test)
y_prediction=[1 if y>= 0.5 else 0   for y in y_prediction]
accuracy_score(y_test, y_prediction)
from sklearn.linear_model import LogisticRegression
clf = LogisticRegression(random_state=0)
logModel=clf.fit(X_train, y_train)
# Accuracy on the train dataset
train_log= logModel.predict(X_train)
accuracy_score(y_train,train_log)
# Accuracy on the test dataset
pred=logModel.predict(X_test)
accuracy_score(y_test,pred)
f1_score(y_test, pred)






